{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"image_segmentation_eval_v1.ipynb의 사본","version":"0.3.2","provenance":[{"file_id":"https://github.com/modulabs/projects4students/blob/master/cnn/image_segmentation/image_segmentation_eval_v1.ipynb","timestamp":1550620914009}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"venv","language":"python","name":"venv"}},"cells":[{"metadata":{"id":"CPwiIjLlNV-b","colab_type":"text"},"cell_type":"markdown","source":["# Image Segmentation for Evaluation\n","\n","* MeanIOU: Image Segmentation에서 많이 쓰이는 evaluation measure\n","* tf.version 1.12 API: [`tf.metrics.mean_iou`](https://www.tensorflow.org/api_docs/python/tf/metrics/mean_iou)\n","  * `tf.enable_eager_execution()`이 작동하지 않음\n","  * 따라서 예전 방식대로 `tf.Session()`을 이용하여 작성하거나 아래와 같이 2.0 version으로 작성하여야 함\n","* tf.version 2.0 API: [`tf.keras.metrics.MeanIoU`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/metrics/MeanIoU)\n","\n","* 지금 이 코드는 `version 1` 코드로 `tf.Session()`을 이용하여 작성"]},{"metadata":{"id":"UfwJVAcDNV-c","colab_type":"text"},"cell_type":"markdown","source":["## Import for Google Colab"]},{"metadata":{"id":"DAkdhtqONV-e","colab_type":"code","colab":{}},"cell_type":"code","source":["# if you necessary\n","\n","#from google.colab import auth\n","#auth.authenticate_user()\n","\n","#from google.colab import drive\n","#drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XH6GHfzJNV-g","colab_type":"code","colab":{}},"cell_type":"code","source":["use_colab = True\n","assert use_colab in [True, False]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Qxz8a6SWNV-k","colab_type":"text"},"cell_type":"markdown","source":["## Import modules"]},{"metadata":{"id":"RQ4Wy0qZNV-k","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import os\n","import time\n","import shutil\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import matplotlib as mpl\n","mpl.rcParams['axes.grid'] = False\n","mpl.rcParams['figure.figsize'] = (12,12)\n","\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","from IPython.display import clear_output\n","\n","import tensorflow as tf\n","\n","from tensorflow.python.keras import layers\n","from tensorflow.python.keras import losses\n","from tensorflow.python.keras import models\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"M1NtjqknNV-m","colab_type":"text"},"cell_type":"markdown","source":["## Load test data"]},{"metadata":{"id":"IuDJ8UbLNV-n","colab_type":"code","colab":{}},"cell_type":"code","source":["if use_colab:\n","  dataset_dir = './gdrive/My Drive/datasets/sd_train'\n","else:\n","  dataset_dir = '../../datasets/sd_train'\n","img_dir = os.path.join(dataset_dir, \"train\")\n","label_dir = os.path.join(dataset_dir, \"train_labels\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3A3ozjwXNV-q","colab_type":"code","colab":{}},"cell_type":"code","source":["x_train_filenames = [os.path.join(img_dir, filename) for filename in os.listdir(img_dir)]\n","x_train_filenames.sort()\n","y_train_filenames = [os.path.join(label_dir, filename) for filename in os.listdir(label_dir)]\n","y_train_filenames.sort()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SRpiS4O9NV-s","colab_type":"code","colab":{}},"cell_type":"code","source":["x_train_filenames, x_test_filenames, y_train_filenames, y_test_filenames = \\\n","                    train_test_split(x_train_filenames, y_train_filenames, test_size=0.2, random_state=219)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pjZRAbJWNV-v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"887c8452-5bff-47cf-e0e7-045ccd3116c5","executionInfo":{"status":"ok","timestamp":1550638001104,"user_tz":-540,"elapsed":3255,"user":{"displayName":"junseop so","photoUrl":"","userId":"03070847090635331575"}}},"cell_type":"code","source":["num_train_examples = len(x_train_filenames)\n","num_test_examples = len(x_test_filenames)\n","\n","print(\"Number of training examples: {}\".format(num_train_examples))\n","print(\"Number of test examples: {}\".format(num_test_examples))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Number of training examples: 240\n","Number of test examples: 60\n"],"name":"stdout"}]},{"metadata":{"id":"njCwdqCmNV-y","colab_type":"text"},"cell_type":"markdown","source":["## Build our input pipeline with `tf.data`\n","### Set up test datasets"]},{"metadata":{"id":"hwzqCQ3MNV-1","colab_type":"code","colab":{}},"cell_type":"code","source":["# Set hyperparameters\n","image_size = 64\n","img_shape = (image_size, image_size, 3)\n","batch_size = 60 # all test dataset"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nI06IHg2NV-4","colab_type":"code","colab":{}},"cell_type":"code","source":["def _process_pathnames(fname, label_path):\n","  # We map this function onto each pathname pair\n","  img_str = tf.io.read_file(fname)\n","  img = tf.image.decode_bmp(img_str, channels=3)\n","\n","  label_img_str = tf.io.read_file(label_path)\n","  label_img = tf.image.decode_bmp(label_img_str, channels=1)\n","  \n","  resize = [image_size, image_size]\n","  img = tf.image.resize_images(img, resize)\n","  label_img = tf.image.resize_images(label_img, resize)\n","  \n","  scale = 1 / 255.\n","  img = tf.to_float(img) * scale\n","  label_img = tf.to_float(label_img) * scale\n","  \n","  return img, label_img"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AXtZ7MqtNV-6","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_baseline_dataset(filenames,\n","                         labels,\n","                         threads=5,\n","                         batch_size=batch_size,\n","                         shuffle=True):\n","  num_x = len(filenames)\n","  # Create a dataset from the filenames and labels\n","  dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n","  # Map our preprocessing function to every element in our dataset, taking\n","  # advantage of multithreading\n","  dataset = dataset.map(_process_pathnames, num_parallel_calls=threads)\n","  \n","  if shuffle:\n","    dataset = dataset.shuffle(num_x * 10)\n","  \n","  dataset = dataset.batch(batch_size)\n","  return dataset"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-03TMIp3NV-8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"eab1012f-914a-47c7-aee8-8c84d1178df1","executionInfo":{"status":"ok","timestamp":1550638001113,"user_tz":-540,"elapsed":3261,"user":{"displayName":"junseop so","photoUrl":"","userId":"03070847090635331575"}}},"cell_type":"code","source":["test_dataset = get_baseline_dataset(x_test_filenames,\n","                                    y_test_filenames,\n","                                    shuffle=False)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-9-9ea8b6e460d2>:14: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"}]},{"metadata":{"id":"z4OLQnBaNV-9","colab_type":"text"},"cell_type":"markdown","source":["## Build the model"]},{"metadata":{"id":"1uDph81tNV--","colab_type":"code","colab":{}},"cell_type":"code","source":["def conv_block(input_tensor, num_filters):\n","  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n","  encoder = layers.BatchNormalization()(encoder)\n","  encoder = layers.Activation('relu')(encoder)\n","  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n","  encoder = layers.BatchNormalization()(encoder)\n","  encoder = layers.Activation('relu')(encoder)\n","  return encoder\n","\n","def encoder_block(input_tensor, num_filters):\n","  encoder = conv_block(input_tensor, num_filters)\n","  encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n","  \n","  return encoder_pool, encoder\n","\n","def decoder_block(input_tensor, concat_tensor, num_filters):\n","  decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n","  decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n","  decoder = layers.BatchNormalization()(decoder)\n","  decoder = layers.Activation('relu')(decoder)\n","  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n","  decoder = layers.BatchNormalization()(decoder)\n","  decoder = layers.Activation('relu')(decoder)\n","  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n","  decoder = layers.BatchNormalization()(decoder)\n","  decoder = layers.Activation('relu')(decoder)\n","  return decoder"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NIOy0g8UNV_A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"f2a43c74-cda1-47cb-8208-36609a4205bd","executionInfo":{"status":"ok","timestamp":1550638001334,"user_tz":-540,"elapsed":3480,"user":{"displayName":"junseop so","photoUrl":"","userId":"03070847090635331575"}}},"cell_type":"code","source":["inputs = layers.Input(shape=img_shape)\n","\n","encoder0_pool, encoder0 = encoder_block(inputs, 64)\n","encoder1_pool, encoder1 = encoder_block(encoder0_pool, 128)\n","encoder2_pool, encoder2 = encoder_block(encoder1_pool, 256)\n","encoder3_pool, encoder3 = encoder_block(encoder2_pool, 512)\n","\n","center = conv_block(encoder3_pool, 1024) # center\n","\n","decoder3 = decoder_block(center, encoder3, 512)\n","decoder2 = decoder_block(decoder3, encoder2, 256)\n","decoder1 = decoder_block(decoder2, encoder1, 128) \n","decoder0 = decoder_block(decoder1, encoder0, 64) \n","\n","outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(decoder0)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"metadata":{"id":"EykRDpHLNV_C","colab_type":"code","colab":{}},"cell_type":"code","source":["model = models.Model(inputs=[inputs], outputs=[outputs])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y-uvzR06NV_G","colab_type":"text"},"cell_type":"markdown","source":["## Restore using Checkpoints (Object-based saving)"]},{"metadata":{"id":"6lR5kWMsNV_H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":232},"outputId":"e96052f8-e4ab-417f-864b-0c0e92fa650d","executionInfo":{"status":"error","timestamp":1550638001609,"user_tz":-540,"elapsed":3754,"user":{"displayName":"junseop so","photoUrl":"","userId":"03070847090635331575"}}},"cell_type":"code","source":["checkpoint_dir = './gdrive/My Drive/train_ckpt/segmentation/exp1'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(model=model)\n","\n","# Restore the latest checkpoint\n","status = checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-15-7da863052e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Restore the latest checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_dir' is not defined"]}]},{"metadata":{"id":"_DEQX8NONV_K","colab_type":"text"},"cell_type":"markdown","source":["## Evaluate the test dataset and Plot"]},{"metadata":{"id":"SWIx8WQcNV_K","colab_type":"code","colab":{}},"cell_type":"code","source":["sess = tf.Session()\n","status.initialize_or_restore(sess)\n","tf.logging.info('Start Session.')\n","\n","test_iter = test_dataset.make_one_shot_iterator()\n","images, targets = test_iter.get_next()\n","\n","mean_iou, mean_iou_op = tf.metrics.mean_iou(labels=tf.to_int32(tf.round(model(images))),\n","                                            predictions=tf.to_int32(tf.round(targets)),\n","                                            num_classes=2,\n","                                            name='mean_iou')\n","sess.run(tf.local_variables_initializer())\n","\n","sess.run(mean_iou_op)\n","print(\"mean iou:\", sess.run(mean_iou))"],"execution_count":0,"outputs":[]}]}